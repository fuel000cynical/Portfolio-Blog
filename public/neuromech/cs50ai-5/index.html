<!DOCTYPE html>
<html><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;600;700;800&family=Frank+Ruhl+Libre:wght@200;300;400;500;600&family=Encode+Sans+Semi+Condensed:wght@400&display=swap" rel="stylesheet">
    
    <link rel="stylesheet" type="text/css" href='http://localhost:1313/css/bootstrap.min.css'>
    <link rel="stylesheet" type="text/css" href='http://localhost:1313/css/all.min.css'>
    <link disabled id="dark-mode-theme" rel="stylesheet" href='http://localhost:1313/css/dark.css'>
    <link rel="stylesheet" type="text/css" href='http://localhost:1313/css/style.css'>
    <link rel="stylesheet" type="text/css" href='http://localhost:1313/css/my_style.css'>
    
    
    
    <title>SG | Neural Networks</title>
    <meta name="description" content="Why Stacking Simple Things Starts Feeling Like Thought - Notes on CS50AI Lecture 5">
</head><body><nav class="navbar navbar-expand-lg navbar-light bg-light">
    <div class="container">
        <a class="navbar-brand" href="http://localhost:1313/">
            
            <b style="font-weight: 800;">SG</b>
            
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNavDropdown">
            <ul class="navbar-nav ms-auto mt-2 mt-lg-0"><li class='nav-item '>
                    <a class="nav-link" href="/neuromech/"> NeuroMech</a>
                </li>
            <li class='nav-item '>
                    <a class="nav-link" href="/juriscript/"> Juriscript</a>
                </li>
            <li class='nav-item '>
                    <a class="nav-link" href="/projects/"> Tech Projects</a>
                </li>
            <li class='nav-item '>
                    <a class="nav-link" href="/about/"> About</a>
                </li>
             
            <li class="nav-item px-2 pt-1">
                <a class="btn fas fa-moon" id="dark-mode-toggle"></a>
            </li>
            </ul>
        </div>
    </div>
</nav><div id="content">

<div class="container" style="max-width: 800px;">
    <div class="py-4 rounded-3">
        <div class="container-fluid py-2">
            <h1 class="display-2 mb-4 text-center">Neural Networks</h1>
        </div>
        
        <p class="text-center fs-4 fst-italic serif">Why Stacking Simple Things Starts Feeling Like Thought - Notes on CS50AI Lecture 5</p>
        
        <div class="text-center pt-4">
            
        </div>
    </div>
    <div class="row justify-content-center mb-5">
        <div class="col-12">
            <p class="card-date m-0">
                
                
                    Created Dec 21, 2025
                
            </p>
            <hr class="dropdown-divider">
            <div class="row justify-content-between">
                <div class="col-sm-4">
                    
                </div>
                <div class="col-sm-8" style="text-align: right;">
                    
                
                
                </div>
            </div>
        </div>
    </div>

    <div class="container-fluid py-2">
        <div class="serif main-content">
            <p>At first, neural networks sound like a metaphor that got out of hand.</p>
<p>We talk about neurons. Layers. Signals. We draw diagrams that vaguely resemble brains. And then we reassure ourselves that none of this is <em>really</em> biology â€” itâ€™s just math. Linear algebra wearing organic metaphors.</p>
<h3 id="cs50ai-lecture5-by-david-jmilan-and-bryan-yu"id="cs50ai-lecture5-by-david-jmilan-and-bryan-yu"
>CS50AI-Lecture5 by David J.Milan and Bryan Yu 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#cs50ai-lecture5-by-david-jmilan-and-bryan-yu&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h3><iframe style="aspect-ratio: 16 / 9; height: 100% !important; width: 45vw;" src="https://www.youtube.com/embed/J1QD9hLDEDY?si=MFU4dk2PBpZQc1Yw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
<br>
<p>Lecture 5 sits right at that tension point.</p>
<p>This is where AI becomes powerful enough to feel uncanny, yet simple enough to feel almost disappointing once you look closely. Nothing in a neural network understands anything. And yet, somehow, meaning begins to emerge.</p>
<p>That contradiction is the heart of this lecture.</p>
<br>
<h1 id="index"id="index"
>Index 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#index&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<ol>
<li><a href="#why-single-models-arent-enough">Why Single Models Arenâ€™t Enough</a></li>
<li><a href="#neural-networks-as-layered-approximation">Neural Networks as Layered Approximation</a></li>
<li><a href="#activation-functions--non-linearity">Activation Functions and Non-Linearity</a></li>
<li><a href="#training-loss-and-backpropagation">Training, Loss, and Backpropagation</a></li>
<li><a href="#gradient-descent-as-slow-adjustment">Gradient Descent as Slow Adjustment</a></li>
<li><a href="#overfitting-capacity-and-depth">Overfitting, Capacity, and Depth</a></li>
<li><a href="#why-neural-networks-feel-different">Why Neural Networks Feel Different</a></li>
<li><a href="#ending-note">Ending Note</a></li>
</ol>
<br>
<p>Up to now, most of the learning models we saw felt limited in very obvious ways. Nearest neighbors needed memory. Perceptrons needed linear separability. Decision trees grew brittle.</p>
<p>Each model failed loudly.</p>
<p>Neural networks fail quietly.</p>
<br>
<h1 id="why-single-models-arent-enough"id="why-single-models-arent-enough"
>Why Single Models Arenâ€™t Enough 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#why-single-models-arent-enough&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>A single perceptron can draw a line. Thatâ€™s its entire worldview.</p>
<p>If the world is separable by straight lines, it works beautifully. If not, it fails completely. There is no graceful degradation. Just wrong answers.</p>
<p>But the real world rarely splits cleanly. Faces are not separated by neat boundaries. Language is not linearly separable. Neither is handwriting, emotion, fraud, or intent.</p>
<p>The response to this limitation is almost embarrassingly simple: stack them.</p>
<p>Instead of one weak model, use many. Let them cooperate. Let their imperfections cancel out.</p>
<br>
<h1 id="neural-networks-as-layered-approximation"id="neural-networks-as-layered-approximation"
>Neural Networks as Layered Approximation 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#neural-networks-as-layered-approximation&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>A neural network is not intelligent. It is <strong>layered approximation</strong>.</p>
<p>Each layer takes a crude guess at representation and passes it forward. The next layer refines that guess slightly. And then slightly more. And then again.</p>
<p>Nothing magical happens at any layer. The magic, if it exists at all, lies in accumulation.</p>
<p>This feels familiar. Humans rarely understand something all at once. We refine. We revise. We misunderstand, then misunderstand less badly.</p>
<p>Neural networks feel powerful not because they reason, but because they <strong>compress complexity across depth</strong>.</p>
<br>
<h1 id="activation-functions--non-linearity"id="activation-functions--non-linearity"
>Activation Functions &amp; Non-Linearity 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#activation-functions--non-linearity&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>Without non-linearity, neural networks collapse into something boring.</p>
<p>Stack linear layers and you still get a linear function. Nothing new emerges. No expressive power is gained.</p>
<p>Activation functions break that monotony.</p>
<p>They introduce bends. Thresholds. Saturation. They force the model to care about some signals and ignore others.</p>
<p>This is where the network stops being a glorified equation and starts behaving like a system with preferences.</p>
<p>ReLU. Sigmoid. Tanh. Each choice encodes assumptions about how signals should behave. None are neutral. All shape what the network can learn.</p>
<p>And this is uncomfortable, because it means <strong>architecture is bias</strong>.</p>
<br>
<h1 id="training-loss-and-backpropagation"id="training-loss-and-backpropagation"
>Training, Loss, and Backpropagation 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#training-loss-and-backpropagation&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>Training a neural network is an exercise in patience.</p>
<p>The system makes a prediction. It is wrong. A number tells it how wrong. That number is loss.</p>
<p>Then comes backpropagation â€” a deeply unintuitive process that nonetheless works astonishingly well. Errors flow backward. Weights adjust. No single neuron knows why it changed. It just did.</p>
<p>This is not reasoning. It is correction without understanding.</p>
<p>And yet, over time, the system improves.</p>
<p>This is where neural networks feel alien. There is no symbolic explanation. Only gradients nudging numbers in directions that happen to reduce error.</p>
<br>
<h1 id="gradient-descent-as-slow-adjustment"id="gradient-descent-as-slow-adjustment"
>Gradient Descent as Slow Adjustment 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#gradient-descent-as-slow-adjustment&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>Gradient descent is not clever. It is stubborn.</p>
<p>It takes small steps. Very small steps. Over and over again.</p>
<p>Too big a step and everything breaks. Too small and nothing happens. Choosing the step size is itself an art, not a science.</p>
<p>This mirrors human learning more than we like to admit. We donâ€™t leap into mastery. We inch forward. We regress. We stall. We adjust.</p>
<p>There is something deeply humbling about the fact that so much modern intelligence is built on such an unglamorous idea.</p>
<br>
<h1 id="overfitting-capacity-and-depth"id="overfitting-capacity-and-depth"
>Overfitting, Capacity, and Depth 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#overfitting-capacity-and-depth&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>With enough layers and enough parameters, a neural network can fit almost anything.</p>
<p>That is not a compliment.</p>
<p>Capacity is power, but it is also danger. A network can learn noise. It can learn bias. It can learn shortcuts that collapse the moment conditions change.</p>
<p>Depth amplifies this risk.</p>
<p>The deeper the network, the harder it becomes to understand what it has learned â€” or why it fails when it does.</p>
<p>And yet, depth also enables abstraction. The same mechanism that hides understanding also creates it.</p>
<p>This tradeoff never disappears. It only becomes harder to manage.</p>
<br>
<h1 id="why-neural-networks-feel-different"id="why-neural-networks-feel-different"
>Why Neural Networks Feel Different 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#why-neural-networks-feel-different&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>Neural networks feel different because they resist explanation.</p>
<p>You cannot point to a single rule and say <em>this is why</em>. You cannot trace a neat decision path. You get weights. Activations. Distributions.</p>
<p>This frustrates lawyers. Regulators. Philosophers. Anyone who wants reasons.</p>
<p>But perhaps that frustration is revealing.</p>
<p>Human decisions are not as transparent as we pretend. We narrate them after the fact. Neural networks simply refuse to play along.</p>
<p>That honesty â€” that opacity â€” is unsettling.</p>
<br>
<h1 id="ending-note"id="ending-note"
>Ending Note 
<button 
    type="button" 
    class="anchor" 
    data-title="Copy link to clipboard" 
    aria-label="Copy link to clipboard"
    onclick="navigator.clipboard.writeText(&#34;http://localhost:1313/neuromech/cs50ai-5/#ending-note&#34;);this.insertAdjacentHTML('afterend', '<div class=link-copied>Link copied</div>');setTimeout(() => { document.querySelectorAll('.link-copied').forEach(el => el.remove()); }, 3000);"
>
    <svg xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 96 960 960" width="1em">
        <path d="M450 776H280q-83 0-141.5-58.5T80 576q0-83 58.5-141.5T280 376h170v60H280q-58.333 0-99.167 40.765-40.833 40.764-40.833 99Q140 634 180.833 675q40.834 41 99.167 41h170v60ZM325 606v-60h310v60H325Zm185 170v-60h170q58.333 0 99.167-40.765 40.833-40.764 40.833-99Q820 518 779.167 477 738.333 436 680 436H510v-60h170q83 0 141.5 58.5T880 576q0 83-58.5 141.5T680 776H510Z"/>
    </svg>
</button>
</h1><hr>
<p>Lecture 5 does not make AI feel smarter. It makes it feel stranger.</p>
<p>Neural networks do not think. They approximate. They compress. They adjust.</p>
<p>And somehow, that is enough to recognize faces, translate languages, and generate text that sounds like thought.</p>
<p>This should not make us worship them. Nor should it make us dismiss them.</p>
<p>It should make us cautious.</p>
<p>Because intelligence, it turns out, may not require understanding at all.</p>
<p>This post is part of my ongoing deep dive into <strong>CS50â€™s Introduction to Artificial Intelligence with Python</strong>, where Iâ€™m documenting my learnings, insights, and interpretations in a practical, simplified form.</p>
<p>If youâ€™re also exploring AI â€” whether as a student, researcher, or just a curious mind â€” Iâ€™d love to connect and exchange ideas.</p>
<p>ðŸ“¬ Letâ€™s connect on LinkedIn: <a href="https://www.linkedin.com/in/soham-gupta-b567b2274/">linkedin</a></p>
<p>More coming soon from future weeks of CS50AI. Stay tuned â€” and stay curious.
â€” <em>Soham Gupta</em></p>
<blockquote>
<p>This post is based on <em><strong><a href="https://cs50.harvard.edu/ai/2024/">CS50â€™s Introduction to Artificial Intelligence with Python</a></strong></em> â€” an open course by Harvard University taught by <strong><a href="https://cs.harvard.edu/malan/">David J. Malan</a></strong> and <strong><a href="https://pll.harvard.edu/instructor/brian-yu/">Brian Yu</a></strong>.</p>
<p>You can explore the course materials <strong><a href="https://github.com/cs50">here on GitHub</a></strong>.</p></blockquote>

        </div>
    </div>
</div>


        </div><div class="container">
    <div class="row justify-content-between">
        <div class="col-sm-4">
            <p class="footer">Soham Gupta Â© 2025 </p>
        </div>
        <div class="col-sm-6 d-flex flex-row-reverse">
            
            <a class="footer-social px-2"  href="https://github.com/fuel000cynical" target="_blank"><i class="fab fa-github"></i></a>
            
            <a class="footer-social px-2"  href="https://www.linkedin.com/in/soham-gupta-b567b2274/" target="_blank"><i class="fab fa-linkedin-in"></i></a>
            
        </div>
    </div>
</div>
<script src='http://localhost:1313/js/bootstrap.min.js'></script>
<script type="text/javascript" src='http://localhost:1313/js/jquery.min.js'></script>
<script src='http://localhost:1313/js/isotope.pkgd.min.js'></script>
<script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous" async></script>
<script src='http://localhost:1313/js/dark.js'></script>
<script>


var savedTheme = localStorage.getItem("dark-mode-storage") || "light" 
setTheme(savedTheme);

</script>
<script src='http://localhost:1313/js/isotope.js'></script>
<script src='http://localhost:1313/js/mermaid.min.js'></script>
<script>mermaid.initialize({ startOnLoad: true, securityLevel: 'loose'});</script>
</body>
</html>
